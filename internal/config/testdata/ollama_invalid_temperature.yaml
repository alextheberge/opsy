ollama:
  enabled: true
  host: http://localhost:11434
  model: codellama:13b
  temperature: 1.5
  max_tokens: 1024
logging:
  level: info
tools:
  exec:
    shell: "/bin/sh"
