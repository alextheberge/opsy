ollama:
  enabled: true
  host: http://localhost:11434
  model: codellama:13b
  temperature: 0.7
  max_tokens: 0
logging:
  level: info
tools:
  exec:
    shell: "/bin/sh"
