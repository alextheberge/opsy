ollama:
  enabled: true
  model: codellama:13b
  temperature: 0.7
  max_tokens: 1024
logging:
  level: info
tools:
  exec:
    shell: "/bin/sh"
